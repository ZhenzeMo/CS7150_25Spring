{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1i6R6xuRpO95",
      "metadata": {
        "id": "1i6R6xuRpO95"
      },
      "source": [
        "# Programming assignment 3: Recurrent Neural Networks and Transformer Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MmDxloX_pO96",
      "metadata": {
        "id": "MmDxloX_pO96"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JMSC7Ha8pO96",
      "metadata": {
        "id": "JMSC7Ha8pO96"
      },
      "source": [
        "<font size='4'>In this assignment you will practice putting together implementations of Recurrent Neural Networks, Transformer Encoder, and their applications to text classification. Especially for Transformer, you will get good understandings about foundations for very state-of-the-art models that you likely to see in tech news articles nowadays, like ChatGPT, Gemini.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "loEOa0hdpO96",
      "metadata": {
        "id": "loEOa0hdpO96"
      },
      "source": [
        "## Submission format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IHB6DeVBpO96",
      "metadata": {
        "id": "IHB6DeVBpO96"
      },
      "source": [
        "- <font size='4'>`<your_nu_username>_pa3.ipynb` with your implementations and output.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DhRQbE3qpO97",
      "metadata": {
        "id": "DhRQbE3qpO97"
      },
      "source": [
        "## Note"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1qj9unjMpO97",
      "metadata": {
        "id": "1qj9unjMpO97"
      },
      "source": [
        "<font size='4'>  \n",
        "\n",
        "- Do not forget to choose to use GPU in the `Runtime\\Change runtime type` tab.    \n",
        "- **You are not allowed to look for answers online. Except for the links provided in this assignment, which are mainly about PyTorch documentation.**\n",
        "- **Violation of this policy will lead to failure of your course and even more severe consequences.**\n",
        "- Attend office hours and make post on Piazza if you have any questions.\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34a5320",
      "metadata": {
        "id": "c34a5320"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7PCioMJW7In",
      "metadata": {
        "id": "f7PCioMJW7In"
      },
      "outputs": [],
      "source": [
        "# Since torchtext has been deprecated, it is not compatible with the latest PyTorch version.\n",
        "# We need to install an old version.\n",
        "# Click to restart the session after the installation when you are prompted to do so.\n",
        "!pip install portalocker==2.6.0\n",
        "!pip install torch==2.1.0 torchtext==0.16.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aOBZrFTopO98",
      "metadata": {
        "id": "aOBZrFTopO98"
      },
      "source": [
        "## Part 1: Text Classification with RNN (32 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fyc3mhNepO98",
      "metadata": {
        "id": "Fyc3mhNepO98"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.datasets import AG_NEWS\n",
        "train_iter = AG_NEWS(split='train')\n",
        "\n",
        "# Let's check what the data looks like\n",
        "print('There are {} training samples in the training set.'.format(len(list(train_iter))))\n",
        "# label, news content\n",
        "print(next(iter(train_iter)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n-36OVgLpO99",
      "metadata": {
        "id": "n-36OVgLpO99"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.1: Implement a RNNCell (6 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r5VgXKB9pO99",
      "metadata": {
        "id": "r5VgXKB9pO99"
      },
      "outputs": [],
      "source": [
        "# Documentation of nn.Module https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\n",
        "class RNNCell(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    RNNCell is a single cell that takes x_t and h_{t_1} as input and outputs h_t.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        Constructor of RNNCell.\n",
        "\n",
        "        Inputs:\n",
        "        - input_dim: Dimension of the input x_t\n",
        "        - hidden_dim: Dimension of the hidden state h_{t-1} and h_t\n",
        "        \"\"\"\n",
        "\n",
        "        # We always need to do this step to properly implement the constructor\n",
        "        super(RNNCell, self).__init__()\n",
        "\n",
        "        self.linear_x, self.linear_h, self.non_linear = None, None, None\n",
        "\n",
        "        ###########################################################################\n",
        "        # TODO: Define the linear transformation layers for x_t and h_{t-1} and   #\n",
        "        # the non-linear layer. You can use tanh here.                            #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "    def forward(self, x_cur: torch.Tensor, h_prev: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute h_t given x_t and h_{t-1}.\n",
        "\n",
        "        Inputs:\n",
        "        - x_cur: x_t, a tensor with the same of BxC, where B is the batch size and\n",
        "          C is the channel dimension.\n",
        "        - h_prev: h_{t-1}, a tensor with the same of BxH, where H is the channel\n",
        "          dimension.\n",
        "        \"\"\"\n",
        "        h_cur = None\n",
        "        ###########################################################################\n",
        "        # TODO: Define the linear transformation layers for x_t and h_{t-1} and   #\n",
        "        # the non-linear layer.                                                   #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        return h_cur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hu4y3bWjpO99",
      "metadata": {
        "id": "Hu4y3bWjpO99"
      },
      "outputs": [],
      "source": [
        "# Let's run a sanity check of your model\n",
        "x = torch.randn((2, 8))\n",
        "h = torch.randn((2, 16))\n",
        "model = RNNCell(8, 16)\n",
        "y = model(x, h)\n",
        "assert len(y.shape) == 2 and y.shape[0] == 2 and y.shape[1] == 16\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OKGmakpGpO99",
      "metadata": {
        "id": "OKGmakpGpO99"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.2: Implement a single-layer (single-stack) RNN (6 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CdoF0E7LpO99",
      "metadata": {
        "id": "CdoF0E7LpO99"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    RNN is a single-layer (stack) RNN by connecting multiple RNNCell together in a single\n",
        "    direction, where the input sequence is processed from left to right.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        Constructor of the RNN module.\n",
        "\n",
        "        Inputs:\n",
        "        - input_dim: Dimension of the input x_t\n",
        "        - hidden_dim: Dimension of the hidden state h_{t-1} and h_t\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        ###########################################################################\n",
        "        # TODO: Define the RNNCell.                                               #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the hidden representations for every token in the input sequence.\n",
        "\n",
        "        Input:\n",
        "        - x: A tensor with the shape of BxLxC, where B is the batch size, L is the squence\n",
        "          length, and C is the channel dimmension\n",
        "\n",
        "        Return:\n",
        "        - h: A tensor with the shape of BxLxH, where H is the hidden dimension of RNNCell\n",
        "        \"\"\"\n",
        "        b = x.shape[0]\n",
        "        seq_len = x.shape[1]\n",
        "\n",
        "        # initialize the hidden dimension\n",
        "        init_h = x.new_zeros((b, self.hidden_dim))\n",
        "\n",
        "        h = None\n",
        "        ###########################################################################\n",
        "        # TODO: Compute the hidden representation for every token in the input    #\n",
        "        # from left to right.\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        return h\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89KpgXuEpO99",
      "metadata": {
        "id": "89KpgXuEpO99"
      },
      "outputs": [],
      "source": [
        "# Let's run a sanity check of your model\n",
        "x = torch.randn((2, 10, 8))\n",
        "model = RNN(8, 16)\n",
        "y = model(x)\n",
        "assert len(y.shape) == 3\n",
        "for dim, dim_gt in zip(y.shape, [2, 10, 16]):\n",
        "    assert dim == dim_gt\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qAJ9zY5cpO9-",
      "metadata": {
        "id": "qAJ9zY5cpO9-"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.3: Implement a RNN-based text classifier (6 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5vGKcHjLpO9-",
      "metadata": {
        "id": "5vGKcHjLpO9-"
      },
      "outputs": [],
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    A RNN-based classifier for text classification. It first converts tokens into word embeddings.\n",
        "    And then feeds the embeddings into a RNN, where the hidden representations of all tokens are\n",
        "    then averaged to get a single embedding of the sentence. It will be used as input to a linear\n",
        "    classifier.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "            vocab_size: int, embed_dim: int, rnn_hidden_dim: int, num_class: int, pad_token: int\n",
        "        ):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "\n",
        "        Inputs:\n",
        "        - vocab_size: Vocabulary size, indicating how many tokens we have in total.\n",
        "        - embed_dim: The dimension of word embeddings\n",
        "        - rnn_hidden_dim: The hidden dimension of the RNN.\n",
        "        - num_class: Number of classes.\n",
        "        - pad_token: The index of the padding token.\n",
        "        \"\"\"\n",
        "        super(RNNClassifier, self).__init__()\n",
        "\n",
        "        # word embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_token)\n",
        "\n",
        "        self.rnn, self.fc = None, None\n",
        "\n",
        "        ###########################################################################\n",
        "        # TODO: Define the RNN and the classification layer.                      #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text):\n",
        "        \"\"\"\n",
        "        Get classification scores (logits) of the input.\n",
        "\n",
        "        Input:\n",
        "        - text: Tensor with the shape of BxLxC.\n",
        "\n",
        "        Return:\n",
        "        - logits: Tensor with the shape of BxK, where K is the number of classes\n",
        "        \"\"\"\n",
        "\n",
        "        # get word embeddings\n",
        "        embedded = self.embedding(text)\n",
        "\n",
        "        logits = None\n",
        "        ###########################################################################\n",
        "        # TODO: Compute logits of the input.                                      #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kKjG-NXHpO9-",
      "metadata": {
        "id": "kKjG-NXHpO9-"
      },
      "outputs": [],
      "source": [
        "# Let's run a sanity check of your model\n",
        "vocab_size = 10\n",
        "embed_dim = 16\n",
        "rnn_hidden_dim = 32\n",
        "num_class = 3\n",
        "\n",
        "x = torch.arange(vocab_size).view(1, -1)\n",
        "x = torch.cat((x, x), dim=0)\n",
        "print('x.shape: {}'.format(x.shape))\n",
        "model = RNNClassifier(vocab_size, embed_dim, rnn_hidden_dim, num_class, 0)\n",
        "y = model(x)\n",
        "assert len(y.shape) == 2 and y.shape[0] == 2 and y.shape[1] == num_class\n",
        "print(y.shape)\n",
        "\n",
        "model = model.to('cuda:0')\n",
        "x = x.to('cuda:0')\n",
        "y = model(x)\n",
        "print(y.shape, y.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M-pySPJQpO9-",
      "metadata": {
        "id": "M-pySPJQpO9-"
      },
      "source": [
        "### Set up data related stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eVTp1entpO9-",
      "metadata": {
        "id": "eVTp1entpO9-"
      },
      "outputs": [],
      "source": [
        "# check here for details https://github.com/pytorch/text/blob/main/torchtext/data/utils.py#L52-#L166\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "# check here for details https://github.com/pytorch/text/blob/main/torchtext/vocab/vocab_factory.py#L65-L113\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# A tokenizer splits a input setence into a set of tokens, including those puncuation\n",
        "# For example\n",
        "# >>> tokens = tokenizer(\"You can now install TorchText using pip!\")\n",
        "# >>> tokens\n",
        "# >>> ['you', 'can', 'now', 'install', 'torchtext', 'using', 'pip', '!']\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "train_iter = AG_NEWS(split='train')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Creates a vocab object which maps tokens to indices\n",
        "# Check here for details https://github.com/pytorch/text/blob/main/torchtext/vocab/vocab.py\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "\n",
        "# The specified token will be returned when a out-of-vocabulary token is queried.\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1\n",
        "\n",
        "# The padding token we need to use\n",
        "# The returned indices are always in an array\n",
        "PAD_TOKEN = vocab(tokenizer('<pad>'))\n",
        "assert len(PAD_TOKEN) == 1\n",
        "PAD_TOKEN = PAD_TOKEN[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3LUrFXDhpO9-",
      "metadata": {
        "id": "3LUrFXDhpO9-"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.4: Collate Batched Data with Data Loaders (5 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5IzWZoFlpO9-",
      "metadata": {
        "id": "5IzWZoFlpO9-"
      },
      "outputs": [],
      "source": [
        "# Documentation of DataLoader https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Merges a list of samples to form a mini-batch of Tensor(s)\n",
        "def collate_batch(batch):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "    - batch: A list of data in a mini batch, where the length denotes the batch size.\n",
        "      The actual context depends on a particular dataset. In our case, each position\n",
        "      contains a label and a Tensor (tokens in a sentence).\n",
        "\n",
        "    Returns:\n",
        "    - batched_label: A Tensor with the shape of (B,)\n",
        "    - batched_text: A Tensor with the shape of (B, L), where L is the sequence length\n",
        "    \"\"\"\n",
        "    label_list, text_list, text_len_list = [], [], []\n",
        "    for (_label, _text) in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        text_len_list.append(processed_text.size(0))\n",
        "    batched_label, batched_text = None, None\n",
        "    ###########################################################################\n",
        "    # TODO: Pad the text tensor in the mini batch so that they have the same  #\n",
        "    # length. Specifically, you need to calculate the maximum length in the   #\n",
        "    # batch and then add the token PAD_TOKEN to the end of those              #\n",
        "    # shorter sentences.                                                      #\n",
        "    ###########################################################################\n",
        "    raise NotImplementedError\n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "\n",
        "    return batched_label.long(), batched_text.long()\n",
        "\n",
        "# Now, let's check what the batched data looks like\n",
        "train_iter = AG_NEWS(split='train')\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
        "for idx, (label, data) in enumerate(dataloader):\n",
        "    if idx > 0:\n",
        "        break\n",
        "    print('label.shape: {}'.format(label.shape))\n",
        "    print('label: {}'.format(label))\n",
        "    print('data.shape: {}'.format(data.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oAJMndQZpO9_",
      "metadata": {
        "id": "oAJMndQZpO9_"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.5: Functions of training for a single epoch and evaluation (5 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IvEW_rrppO9_",
      "metadata": {
        "id": "IvEW_rrppO9_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(model, dataloader, loss_func, device, grad_norm_clip):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text) in enumerate(dataloader):\n",
        "        label = label.to(device)\n",
        "        text = text.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = None\n",
        "        ###########################################################################\n",
        "        # TODO: compute the logits of the input, get the loss, and do the         #\n",
        "        # gradient backpropagation.\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
        "        optimizer.step()\n",
        "        total_acc += (logits.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model, dataloader, loss_func, device):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text) in enumerate(dataloader):\n",
        "            label = label.to(device)\n",
        "            text = text.to(device)\n",
        "\n",
        "            ###########################################################################\n",
        "            # TODO: compute the logits of the input, get the loss.                    #\n",
        "            ###########################################################################\n",
        "            raise NotImplementedError\n",
        "            ###########################################################################\n",
        "            #                             END OF YOUR CODE                            #\n",
        "            ###########################################################################\n",
        "\n",
        "            total_acc += (logits.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DdeBRvT-pO9_",
      "metadata": {
        "id": "DdeBRvT-pO9_"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.6: Define the model, loss function, optimizer, and learning rate scheduler. You do not have to tune the hyperparameters here (our implementation is not optimal and thus slow). You should achieve 87% validation accuracy. (4 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N-LxJ_mppO9_",
      "metadata": {
        "id": "N-LxJ_mppO9_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "# device = 'cuda'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# hyper parameters\n",
        "epochs = 3 # epoch\n",
        "lr = 0.0005 # learning rate\n",
        "batch_size = 64 # batch size for training\n",
        "word_embed_dim = 64\n",
        "rnn_hidden_dim = 96\n",
        "\n",
        "\n",
        "train_iter = AG_NEWS(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "model, loss_func = None, None\n",
        "###########################################################################\n",
        "# TODO: Deinfe the classifier, loss function, optimizer, and lr_scheduler.\n",
        "# You are encouraged to use the AdamW optimizer and find a suitable       #\n",
        "# learning rate scheduler for it.                                         #\n",
        "###########################################################################\n",
        "raise NotImplementedError\n",
        "###########################################################################\n",
        "#                             END OF YOUR CODE                            #\n",
        "###########################################################################\n",
        "\n",
        "# copy the model to the specified device (GPU)\n",
        "model = model.to(device)\n",
        "\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print('Number of parameters: {:.3f}K'.format(num_params / 1000))\n",
        "\n",
        "total_accu = None\n",
        "train_iter, test_iter = AG_NEWS()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train, split_valid = random_split(\n",
        "    train_dataset,\n",
        "    [num_train, len(train_dataset) - num_train]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train, batch_size=batch_size,\n",
        "    shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid, batch_size=batch_size,\n",
        "    shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size,\n",
        "    shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "# You should be able get a validation accuracy around 87%\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model, train_dataloader, loss_func, device, 1)\n",
        "    accu_val = evaluate(model, valid_dataloader, loss_func, device)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "E3K4z5LbpO9_",
      "metadata": {
        "id": "E3K4z5LbpO9_"
      },
      "source": [
        "## Part 2: Text Classification with Transformer Encoder (68 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mAA3WK4WpO9_",
      "metadata": {
        "id": "mAA3WK4WpO9_"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.1: Implement the multi-head attention module. No for are loops allowed. (15 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jb1_cmOApO9_",
      "metadata": {
        "id": "jb1_cmOApO9_"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    A module that computes multi-head attention given query, key, and value tensors.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, num_heads: int):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "\n",
        "        Inputs:\n",
        "        - input_dim: Dimension of the input query, key, and value. Here we assume they all have\n",
        "          the same dimensions. But they could have different dimensions in other problems.\n",
        "        - num_heads: Number of attention heads\n",
        "        \"\"\"\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        assert input_dim % num_heads == 0\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.num_heads = num_heads\n",
        "        # channel dimension per attention head\n",
        "        self.dim_per_head = input_dim // num_heads\n",
        "\n",
        "        ###########################################################################\n",
        "        # TODO: Define the linear transformation layers for key, value, and query.#\n",
        "        # Also define the output layer.\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "\n",
        "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, mask: torch.Tensor=None):\n",
        "        \"\"\"\n",
        "        Compute the attended feature representations.\n",
        "\n",
        "        Inputs:\n",
        "        - query: Tensor of the shape BxLxC, where B is the batch size, L is the sequence length,\n",
        "          and C is the channel dimension\n",
        "        - key: Tensor of the shape BxLxC\n",
        "        - value: Tensor of the shape BxLxC\n",
        "        - mask: Tensor indicating where the attention should *not* be performed\n",
        "        \"\"\"\n",
        "        b = query.shape[0]\n",
        "\n",
        "        dot_prod_scores = None\n",
        "        ###########################################################################\n",
        "        # TODO: Compute the scores based on dot product between transformed query,#\n",
        "        # key, and value. You may find torch.matmul helpful, whose documentation  #\n",
        "        # can be found at                                                         #\n",
        "        # https://pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmul#\n",
        "        # Remember to divide the dot product similarity scores by square root of  #\n",
        "        # the channel dimension per head.\n",
        "        #                                                                         #\n",
        "        # Since no for loops are allowed here, think of how to use tensor reshape #\n",
        "        # to process multiple attention heads at the same time.                   #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        if mask is not None:\n",
        "            # We simply set the similarity scores to be near negative infinity for\n",
        "            # the positions where the attention should not be done. Think of why  #\n",
        "            # we do this.\n",
        "            dot_prod_scores = dot_prod_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        out = None\n",
        "        ###########################################################################\n",
        "        # TODO: Compute the attention scores, which are then used to modulate the #\n",
        "        # value tensor. Finally concatenate the attended tensors from multiple    #\n",
        "        # heads and feed it into the output layer. You may still find             #\n",
        "        # torch.matmul helpful.                                                   #\n",
        "        #                                                                         #\n",
        "        # Again, think of how to use reshaping tensor to do the concatenation.    #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BNZFhiD6pO9_",
      "metadata": {
        "id": "BNZFhiD6pO9_"
      },
      "outputs": [],
      "source": [
        "x = torch.randn((2, 10, 8))\n",
        "mask = torch.randn((2, 10)) > 0.5\n",
        "mask = mask.unsqueeze(1).unsqueeze(-1)\n",
        "num_heads = 4\n",
        "model = MultiHeadAttention(8, num_heads)\n",
        "y = model(x, x, x, mask)\n",
        "assert len(y.shape) == len(x.shape)\n",
        "for dim_x, dim_y in zip(x.shape, y.shape):\n",
        "    assert dim_x == dim_y\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_nFdhQN_pO-A",
      "metadata": {
        "id": "_nFdhQN_pO-A"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.2: Implement a Feedforward Network (4 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PGbkqhXOpO-A",
      "metadata": {
        "id": "PGbkqhXOpO-A"
      },
      "outputs": [],
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple feedforward network. Essentially, it is a two-layer fully-connected\n",
        "    neural network.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, ff_dim, dropout):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - input_dim: Input dimension\n",
        "        - ff_dim: Hidden dimension\n",
        "        \"\"\"\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "\n",
        "        ###########################################################################\n",
        "        # TODO: Define the two linear layers and a non-linear one.\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - x: Tensor of the shape BxLxC, where B is the batch size, L is the sequence length,\n",
        "         and C is the channel dimension\n",
        "\n",
        "        Return:\n",
        "        - y: Tensor of the shape BxLxC\n",
        "        \"\"\"\n",
        "\n",
        "        y = None\n",
        "        ###########################################################################\n",
        "        # TODO: Process the input.                                                #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XKzQuXLfpO-A",
      "metadata": {
        "id": "XKzQuXLfpO-A"
      },
      "outputs": [],
      "source": [
        "x = torch.randn((2, 10, 8))\n",
        "ff_dim = 4\n",
        "model = FeedForwardNetwork(8, ff_dim, 0.1)\n",
        "y = model(x)\n",
        "assert len(x.shape) == len(y.shape)\n",
        "for dim_x, dim_y in zip(x.shape, y.shape):\n",
        "    assert dim_x == dim_y\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "chABAxXSpO-A",
      "metadata": {
        "id": "chABAxXSpO-A"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.3: Implement a single Transformer Encoder Cell using post layer normalization (15 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5UbS7RbSpO-A",
      "metadata": {
        "id": "5UbS7RbSpO-A"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderCell(nn.Module):\n",
        "    \"\"\"\n",
        "    A single cell (unit) for the Transformer encoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, num_heads: int, ff_dim: int, dropout: float):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - input_dim: Input dimension for each token in a sequence\n",
        "        - num_heads: Number of attention heads in a multi-head attention module\n",
        "        - ff_dim: The hidden dimension for a feedforward network\n",
        "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
        "          modules.\n",
        "        \"\"\"\n",
        "        super(TransformerEncoderCell, self).__init__()\n",
        "\n",
        "        ###########################################################################\n",
        "        # TODO: A single Transformer encoder cell consists of\n",
        "        # 1. A multi-head attention module\n",
        "        # 2. Followed by dropout\n",
        "        # 3. Followed by layer norm (check nn.LayerNorm)\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm\n",
        "\n",
        "        # At the same time, it also has\n",
        "        # 1. A feedforward network\n",
        "        # 2. Followed by dropout\n",
        "        # 3. Followed by layer norm\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "    def forward(self, x: torch.Tensor, mask: torch.Tensor=None):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - x: Tensor of the shape BxLxC, where B is the batch size, L is the sequence length,\n",
        "          and C is the channel dimension\n",
        "        - mask: Tensor for masking in the multi-head attention\n",
        "        \"\"\"\n",
        "\n",
        "        y = None\n",
        "        ###########################################################################\n",
        "        # TODO: Get the output of the multi-head attention part (with dropout     #\n",
        "        # and layer norm), which is used as input to the feedforward network (    #\n",
        "        # again, followed by dropout and layer norm).                             #\n",
        "        #                                                                         #\n",
        "        # Don't forget the residual connections for both parts.                   #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9IhLjOnNpO-A",
      "metadata": {
        "id": "9IhLjOnNpO-A"
      },
      "outputs": [],
      "source": [
        "x = torch.randn((2, 10, 8))\n",
        "mask = torch.randn((2, 10)) > 0.5\n",
        "mask = mask.unsqueeze(1).unsqueeze(-1)\n",
        "num_heads = 4\n",
        "model = TransformerEncoderCell(8, num_heads, 32, 0.1)\n",
        "y = model(x, mask)\n",
        "assert len(x.shape) == len(y.shape)\n",
        "for dim_x, dim_y in zip(x.shape, y.shape):\n",
        "    assert dim_x == dim_y\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WfMGj10tpO-A",
      "metadata": {
        "id": "WfMGj10tpO-A"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.4: Implement Transformer Encoder (8 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c_lgSBXbpO-H",
      "metadata": {
        "id": "c_lgSBXbpO-H"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A full encoder consisting of a set of TransformerEncoderCell.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, num_heads: int, ff_dim: int, num_cells: int, dropout: float=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - input_dim: Input dimension for each token in a sequence\n",
        "        - num_heads: Number of attention heads in a multi-head attention module\n",
        "        - ff_dim: The hidden dimension for a feedforward network\n",
        "        - num_cells: Number of TransformerEncoderCells\n",
        "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
        "          modules.\n",
        "        \"\"\"\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "\n",
        "        self.norm = None\n",
        "        ###########################################################################\n",
        "        # TODO: Construct a nn.ModuleList to store a stack of                     #\n",
        "        # TranformerEncoderCells. Check the documentation here of how to use it   #\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList\n",
        "\n",
        "        # At the same time, define a layer normalization layer to process the     #\n",
        "        # output of the entire encoder.                                           #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "    def forward(self, x: torch.Tensor, mask: torch.Tensor=None):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - x: Tensor of the shape BxLxC, where B is the batch size, L is the sequence length,\n",
        "          and C is the channel dimension\n",
        "        - mask: Tensor for masking in the multi-head attention\n",
        "\n",
        "        Return:\n",
        "        - y: Tensor of the shape of BxLxC, which is the normalized output of the encoder\n",
        "        \"\"\"\n",
        "\n",
        "        y = None\n",
        "        ###########################################################################\n",
        "        # TODO: Feed x into the stack of TransformerEncoderCells and then         #\n",
        "        # normalize the output with layer norm.                                   #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P87ZL-xUpO-H",
      "metadata": {
        "id": "P87ZL-xUpO-H"
      },
      "outputs": [],
      "source": [
        "x = torch.randn((2, 10, 8))\n",
        "mask = torch.randn((2, 10)) > 0.5\n",
        "mask = mask.unsqueeze(1).unsqueeze(-1)\n",
        "num_heads = 4\n",
        "model = TransformerEncoder(8, num_heads, 32, 2, 0.1)\n",
        "y = model(x)\n",
        "assert len(x.shape) == len(y.shape)\n",
        "for dim_x, dim_y in zip(x.shape, y.shape):\n",
        "    assert dim_x == dim_y\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sGd6at2IpO-H",
      "metadata": {
        "id": "sGd6at2IpO-H"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.5: Implement Positional Encoding (10 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vQp7GgF8pO-H",
      "metadata": {
        "id": "vQp7GgF8pO-H"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    A module that adds positional encoding to each of the token's features.\n",
        "    So that the Transformer is position aware.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, max_len: int=10000):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - input_dim: Input dimension about the features for each token\n",
        "        - max_len: The maximum sequence length\n",
        "        \"\"\"\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "    def forward(self, x, max_length=10000):\n",
        "        \"\"\"\n",
        "        Compute the positional encoding and add it to x.\n",
        "\n",
        "        Input:\n",
        "        - x: Tensor of the shape BxLxC, where B is the batch size, L is the sequence length,\n",
        "          and C is the channel dimension\n",
        "        - max_length: maximum sequence length the positional encoding can handle\n",
        "\n",
        "        Return:\n",
        "        - x: Tensor of the shape BxLxC, with the positional encoding added to the input\n",
        "        \"\"\"\n",
        "        seq_len = x.shape[1]\n",
        "        input_dim = x.shape[2]\n",
        "\n",
        "        pe = None\n",
        "        ###########################################################################\n",
        "        # TODO: Compute the positional encoding                                   #\n",
        "        # Check Section 3.5 for the definition (https://arxiv.org/pdf/1706.03762.pdf)\n",
        "        #                                                                         #\n",
        "        # It's a bit messy, but the definition is provided for your here for your #\n",
        "        # convenience (in LaTex).                                                 #\n",
        "        # PE_{(pos,2i)} = sin(pos / 10000^{2i/\\dmodel}) \\\\                        #\n",
        "        # PE_{(pos,2i+1)} = cos(pos / 10000^{2i/\\dmodel})                         #\n",
        "        #                                                                         #\n",
        "        # You should replace 10000 with max_len here.\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        x = x + pe.to(x.device)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nNO57K2_pO-H",
      "metadata": {
        "id": "nNO57K2_pO-H"
      },
      "outputs": [],
      "source": [
        "# Sanity check\n",
        "x = torch.randn(1, 100, 20)\n",
        "pe = PositionalEncoding(20)\n",
        "y = pe(x)\n",
        "assert len(x.shape) == len(y.shape)\n",
        "for dim_x, dim_y in zip(x.shape, y.shape):\n",
        "    assert dim_x == dim_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UNXa9j7BpO-H",
      "metadata": {
        "id": "UNXa9j7BpO-H"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "pe = PositionalEncoding(20, 0)\n",
        "y = pe.forward((torch.zeros(1, 100, 20)))\n",
        "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
        "plt.legend([\"dim %d\"%p for p in [4,5,6,7]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vSYO_F1RpO-H",
      "metadata": {
        "id": "vSYO_F1RpO-H"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.6: Implement a Transformer-based Text Classifier (6 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rcUBBUW-pO-H",
      "metadata": {
        "id": "rcUBBUW-pO-H"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    A Transformer-based text classifier.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "            vocab_size: int, embed_dim: int, num_heads: int, trx_ff_dim: int,\n",
        "            num_trx_cells: int, num_class: int, dropout: float=0.1, pad_token: int=0\n",
        "        ):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - vocab_size: Vocabulary size, indicating how many tokens we have in total.\n",
        "        - embed_dim: The dimension of word embeddings\n",
        "        - num_heads: Number of attention heads in a multi-head attention module\n",
        "        - trx_ff_dim: The hidden dimension for a feedforward network\n",
        "        - num_trx_cells: Number of TransformerEncoderCells\n",
        "        - dropout: Dropout ratio\n",
        "        - pad_token: The index of the padding token.\n",
        "        \"\"\"\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.pad_token = pad_token\n",
        "\n",
        "        # word embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_token)\n",
        "\n",
        "        ###########################################################################\n",
        "        # TODO: Define a module for positional encoding, Transformer encoder, and #\n",
        "        # a output layer                                                          #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "    def forward(self, text, mask=None):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - text: Tensor with the shape of BxL, containing the indexes of each word in\n",
        "          the vocabulary, which will be converted into word embeddings with the shape\n",
        "          of BxLxC\n",
        "        - mask: Tensor for masking in the multi-head attention\n",
        "\n",
        "        Return:\n",
        "        - logits: Tensor with the shape of BxK, where K is the number of classes\n",
        "        \"\"\"\n",
        "\n",
        "        # word embeddings, note we multiple the embeddings by a factor\n",
        "        embedded = self.embedding(text) * math.sqrt(self.embed_dim)\n",
        "        if mask is None:\n",
        "          mask = (text != self.pad_token).unsqueeze(-2).unsqueeze(1)\n",
        "\n",
        "        logits = None\n",
        "        ###########################################################################\n",
        "        # TODO: Apply positional embedding to the input, which is then fed into   #\n",
        "        # the encoder. Average pooling is applied then to all the features of all #\n",
        "        # tokens. Finally, the logits are computed based on the pooled features.  #\n",
        "        ###########################################################################\n",
        "        raise NotImplementedError\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MVx7PF0UpO-H",
      "metadata": {
        "id": "MVx7PF0UpO-H"
      },
      "outputs": [],
      "source": [
        "vocab_size = 10\n",
        "embed_dim = 16\n",
        "num_heads = 2\n",
        "trx_ff_dim = 32\n",
        "num_trx_cells = 2\n",
        "num_class = 3\n",
        "\n",
        "x = torch.arange(vocab_size).view(1, -1)\n",
        "x = torch.cat((x, x), dim=0)\n",
        "mask = (x != 0).unsqueeze(-2).unsqueeze(1)\n",
        "model = TransformerClassifier(vocab_size, embed_dim, num_heads, trx_ff_dim, num_trx_cells, num_class)\n",
        "print('x: {}, mask: {}'.format(x.shape, mask.shape))\n",
        "y = model(x, mask)\n",
        "assert len(y.shape) == 2 and y.shape[0] == x.shape[0] and y.shape[1] == num_class\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c1Q-6PHpO-I",
      "metadata": {
        "id": "9c1Q-6PHpO-I"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.7: Define the model, loss function, optimizer, and learning rate scheduler. And then tune the hyperparameters to train the model. You need to achieve 89% validation accuracy. (10 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C0yid6zKpO-I",
      "metadata": {
        "id": "C0yid6zKpO-I"
      },
      "outputs": [],
      "source": [
        "assert torch.cuda.is_available()\n",
        "# device = 'cuda'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Hyperparameters\n",
        "# Let's use a fixed number of epochs\n",
        "epochs = 3 # epoch\n",
        "###########################################################################\n",
        "# TODO: Tune the hyper parameters\n",
        "###########################################################################\n",
        "# learning rate\n",
        "lr = 1\n",
        "batch_size = 1\n",
        "# dimension of word embedding dimension\n",
        "word_embed_dim = 1\n",
        "# feedforward hidden dimension\n",
        "ff_dim = 1\n",
        "# number of attention heads\n",
        "num_heads = 1\n",
        "# number of Transformer Encoder cells to stack\n",
        "num_trx_cells = 1\n",
        "###########################################################################\n",
        "#                             END OF YOUR CODE                            #\n",
        "###########################################################################\n",
        "\n",
        "train_iter = AG_NEWS(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "gradient_norm_clip = 10\n",
        "\n",
        "model = None\n",
        "loss_func = None\n",
        "optimizer = None\n",
        "scheduler = None\n",
        "###########################################################################\n",
        "# Define a Transformer-based text classifier, a loss function, optimizer, #\n",
        "# and learning rate scheduler.                                            #\n",
        "###########################################################################\n",
        "raise NotImplementedError\n",
        "###########################################################################\n",
        "#                             END OF YOUR CODE                            #\n",
        "###########################################################################\n",
        "model = model.to(device)\n",
        "\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print('Number of parameters: {:.3f}K'.format(num_params / 1000))\n",
        "\n",
        "num_params = sum(p.numel() for p in model.embedding.parameters())\n",
        "print('Number of parameters: {:.3f}K'.format(num_params / 1000))\n",
        "\n",
        "# splits have been created in the RNN part\n",
        "train_dataloader = DataLoader(\n",
        "    split_train, batch_size=batch_size,\n",
        "    shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid, batch_size=batch_size,\n",
        "    shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size,\n",
        "    shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "total_accu = None\n",
        "\n",
        "# You should be able to get a validation accuracy around 89%\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model, train_dataloader, loss_func, device, gradient_norm_clip)\n",
        "    accu_val = evaluate(model, valid_dataloader, loss_func, device)\n",
        "    scheduler.step()\n",
        "    # if total_accu is not None and total_accu > accu_val:\n",
        "    #     scheduler.step()\n",
        "    # else:\n",
        "    #     total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Iyly9cWxpO-I",
      "metadata": {
        "id": "Iyly9cWxpO-I"
      },
      "source": [
        "## <font color='red'> Part 3: Extra Credits: Image Classification with Transformer (14 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ry2-iCYXpO-I",
      "metadata": {
        "id": "Ry2-iCYXpO-I"
      },
      "source": [
        "### <font size='4' color='red'>Implement VisionTransformer (ViT) for Image Classification. Train it on the CIFAR10 dataset (you may find the helper functions used in the previous programming assignment helpful). To get the full credits, you need to achieve 50% validation accuracy. No partial credits will be given if your accuracy is below 50%. Note the following comments and constraints:\n",
        "- You need to implement a variant of the pre-norm Transformer cell shown in Fig. 1 of https://arxiv.org/pdf/2010.11929 (post-norm does not work well here).\n",
        "- The number of parameters should be smaller than 3.2M.\n",
        "- No pre-trained weights are allowed.\n",
        "- Training has to finish within 3 epochs.\n",
        "- Do not override any previous functions. Instead, re-implement a new one below if necessary.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f910d4",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
