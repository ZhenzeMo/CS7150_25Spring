{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30ddad3",
   "metadata": {
    "id": "c30ddad3"
   },
   "source": [
    "# Programming Assignment 5: Diffusion Models (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b0c80e",
   "metadata": {
    "id": "69b0c80e"
   },
   "source": [
    "# Overview\n",
    "\n",
    "<font size='4'>In this assignment, you will practice implementing [DDPM](https://arxiv.org/pdf/2006.11239) (denoising diffusion probabilistic models) for grayscale image generation. After finishing this programming assignment, you will get good understandings about foundations for very state-of-the-art image generation models that you likely see in tech news articles nowadays, like Stable Diffusion, Sora.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88244be3",
   "metadata": {},
   "source": [
    "## Submission format\n",
    "\n",
    "<font size='4'>`<your_nu_username>_pa5.ipynb` with your implementations and output.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68922c",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "<font size='4'>  \n",
    "\n",
    "- **Read the instructions and comments very carefully to avoid waste of your valuable time and deduction of points.**\n",
    "\n",
    "- You do not install any additional packages inside the Colab environment. Do not forget to choose to use GPU in the `Runtime\\Change runtime type` tab.    \n",
    "\n",
    "- **You are not allowed to look for answers online, except for the links provided in this assignment.**\n",
    "\n",
    "- **Violation of this policy will lead to failure of your course and even more severe consequences.**\n",
    "\n",
    "- **Only work on it when you have bandwidth since you may loose more for the final project than what you can get here.**\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1cbde6",
   "metadata": {
    "id": "3d1cbde6"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b9e321",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8b9e321",
    "outputId": "e1279c20-7a47-4e9b-9ea1-17977c10cff4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('We are using the device {}.'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf35a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using a subset of the MNIST dataset \n",
    "# (https://en.wikipedia.org/wiki/MNIST_database#:~:text=The%20MNIST%20database%20(Modified%20National,training%20various%20image%20processing%20systems.).\n",
    "# To save some computation burden, we will only be using images with labels of 0 and 1.\n",
    "\n",
    "class SubsetMNIST(MNIST):\n",
    "    @property\n",
    "    def raw_folder(self) -> str:\n",
    "        return os.path.join(self.root, 'MNIST', \"raw\")\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "        root: Union[str, Path],\n",
    "        train: bool = True,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "        download: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__(\n",
    "            root, transform=transform,\n",
    "            target_transform=target_transform,\n",
    "            download=download\n",
    "        )\n",
    "\n",
    "        sub_data = []\n",
    "        sub_targets = []\n",
    "        n_total = len(self.data)\n",
    "        for i in range(n_total):\n",
    "            if self.targets[i] in [0, 1]:\n",
    "                sub_data.append(self.data[i])\n",
    "                sub_targets.append(self.targets[i])\n",
    "\n",
    "        self.data = sub_data\n",
    "        self.targets = sub_targets\n",
    "\n",
    "dataset = SubsetMNIST(\n",
    "    \"./data\",\n",
    "    train=True,\n",
    "    download=True\n",
    ")\n",
    "print(f'There are {len(dataset)} images in total.')\n",
    "\n",
    "num_show = 16\n",
    "show_im_zero = np.zeros((num_show // 2, 1, 28, 28))\n",
    "show_im_one = np.zeros((num_show // 2, 1, 28, 28))\n",
    "num_zero = 0\n",
    "num_one = 0\n",
    "# randomly sample images\n",
    "for data, label in dataset:\n",
    "    if label  == 0 and num_zero < num_show // 2:\n",
    "        show_im_zero[num_zero, :] = data\n",
    "        num_zero += 1\n",
    "    if label == 1 and num_one < num_show // 2:\n",
    "        show_im_one[num_one, :] = data\n",
    "        num_one += 1\n",
    "\n",
    "# let's take a look at what the training data looks like\n",
    "show_im = np.concatenate((show_im_zero, show_im_one), axis=0)\n",
    "show_im = make_grid(torch.from_numpy(show_im), nrow=4, normalize=True)\n",
    "plt.imshow(show_im.numpy().transpose(1, 2, 0))\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62205a50",
   "metadata": {
    "id": "62205a50"
   },
   "source": [
    "## <font color='red'>Task 1: Implement a UNet (5 points). </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jar2i6XnkfG7",
   "metadata": {
    "id": "jar2i6XnkfG7"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A UNet model that takes an image as input and output another image with the \n",
    "    **same** spatial dimension.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes, inter_planes=128):\n",
    "        super(UNet, self).__init__()\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          - in_planes: number of channels in the input\n",
    "          - inter_planes: a base number for number of channels in the intermediate\n",
    "            output of the UNet\n",
    "        \"\"\"\n",
    "        \n",
    "        # encoder with 3 blocks\n",
    "        self.block1 = None\n",
    "        self.block2 = None\n",
    "        self.block3 = None\n",
    "        \n",
    "        # decoder with another 3 blocks\n",
    "        self.block4 = None\n",
    "        self.block5 = None\n",
    "        self.block6 = None\n",
    "        \n",
    "        # output layer\n",
    "        self.out_layer = None\n",
    "\n",
    "        ###########################################################################\n",
    "        # TODO: Implement all blocks and the output layer. For each block in the  #\n",
    "        # encoder, the downsampling factor should be 2. So for an MNIST images of #\n",
    "        # 28x28, the output dimensions of the three blocks should be 14x14, 7x7,  #\n",
    "        # and 4x4, respectively. For each block in the decoder, we do upsampling  # \n",
    "        # with a factor of 2. Check torch.nn.Sample on how to do it. You can also #\n",
    "        # do upsampling using torch.nn.functional.interpolate in the forward()    #\n",
    "        # function. Recall a critical design in UNet is to fuse the features      #\n",
    "        # with the same spatial dimensions across the encoder and decoder. Here   #\n",
    "        # we can concatenate them along the channel dimension. The channel        #\n",
    "        # dimensions across the six blocks should be inter_planes, 2*inter_planes,#\n",
    "        # 4*inter_planes, 4*inter_planes, 2*inter_planes, and inter_planes,       #\n",
    "        # respectively.                                                           #\n",
    "        #                                                                         #\n",
    "        # Also implement the output layer. The total number of parameters should  #\n",
    "        # be smaller than 15M.                                                    #\n",
    "        #                                                                         #\n",
    "        # You are encouraged to experiment with different ways of composing the   #\n",
    "        # blocks.                                                                 #\n",
    "        ###########################################################################\n",
    "\t\traise NotImplementedError\n",
    "        ###########################################################################\n",
    "        #                             END OF YOUR CODE                            #\n",
    "        ###########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward process of the UNet.\n",
    "        Input:\n",
    "          - x: shape of BxCxHxW, input images\n",
    "          - y: shape of BxCxHxW, output images\n",
    "        \"\"\"\n",
    "        \n",
    "        output = None\n",
    "        ###########################################################################\n",
    "        # TODO: Implement the forward process of the UNet.                        #\n",
    "        ###########################################################################\n",
    "        raise NotImplementedError\n",
    "        ###########################################################################\n",
    "        #                             END OF YOUR CODE                            #\n",
    "        ###########################################################################\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PAFYsnHvyCGP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAFYsnHvyCGP",
    "outputId": "c4ac5c77-cf5e-4233-a998-0f4553cd9d3b"
   },
   "outputs": [],
   "source": [
    "# sanity check of tensor shapes\n",
    "x = torch.randn((3, 1, 28, 28))\n",
    "model = UNet(1)\n",
    "y = model(x)\n",
    "for dim_y, dim_x in zip(y.shape, x.shape):\n",
    "    assert dim_y == dim_x\n",
    "print('output shape: ', y.shape)\n",
    "num_params = sum(p.numel() / 1000000 for p in model.parameters())\n",
    "assert num_params < 15\n",
    "print('Num parameters: {:.2f}M'.format(num_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f26c0c",
   "metadata": {
    "id": "e7f26c0c"
   },
   "source": [
    "## <font color='red'> Task 2: Implement DDPM for both the $x_0$ and $\\epsilon$ variants (8 points).</font>\n",
    "\n",
    "<font size='4' color='red'>\n",
    "Some important notes before you start implementing the DDPM model. Read them carefully.\n",
    "</font>\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "- We will mostly follow the tutorial https://arxiv.org/pdf/2403.18103. \n",
    "\n",
    "- There is a typo in the training algorithm on Page 36. It should be\n",
    "$$\n",
    "\\mathbf{x}_t^{(m)} = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t}\\mathbf{\\epsilon}^{(m)}.\n",
    "$$\n",
    "\n",
    "- For both the inference algorithms on Page 37 and Page 39, we will simply define $\\sigma_q(t) = 1 - \\alpha_t$.\n",
    "\n",
    "- We will mostly use the notations in the tutorial. In the literature and the original paper of DDPM (https://arxiv.org/pdf/2006.11239), you will see $\\beta_t$, which is simply defined $\\beta_t = 1 - \\alpha_t$.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wj_psXC9olIx",
   "metadata": {
    "id": "Wj_psXC9olIx"
   },
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    \"\"\"\n",
    "    Class of denoising diffusion probabilistic model (DDPM).\n",
    "    The original paper is at https://arxiv.org/pdf/2006.11239.\n",
    "    But you are encouraged to read the tutorial https://arxiv.org/pdf/2403.18103\n",
    "    for detailed mathematical derivations.\n",
    "    In this implementation, we will use a linear scheduler for the noise between\n",
    "    alpha_1 and alpha_T.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            unet: nn.Module,\n",
    "            alpha_1: float,\n",
    "            alpha_T: float,\n",
    "            T: int,\n",
    "            criterion: nn.Module,\n",
    "            denoising_objective: str = 'x_zero',\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          - unet: A UNet model.\n",
    "          - alpha_1: a scalar denoting the smallest alpha value\n",
    "          - alpha_T: a scalar denoting the largest alpha value\n",
    "          - T: number of denoising diffusion steps\n",
    "          - criterion: a torch.nn.Module denoting the loss function\n",
    "          - denoising_objective: a string denoting the denoising objective: x_zero or epsilon\n",
    "        \"\"\"\n",
    "        super(DDPM, self).__init__()\n",
    "\n",
    "        self.unet = unet\n",
    "        self.alpha_1 = alpha_1\n",
    "        self.alpha_T = alpha_T\n",
    "        self.T = T\n",
    "        self.criterion = criterion\n",
    "        assert denoising_objective in ['x_zero', 'epsilon']\n",
    "        self.denoising_objective = denoising_objective\n",
    "\n",
    "        # hard-coded image spatial dimension for MNIST\n",
    "        self.im_size = (28, 28)\n",
    "\n",
    "        # a linear noise scheduler\n",
    "        alpha_t_list = (alpha_1 - alpha_T) * torch.arange(0, T + 1, dtype=torch.float32) / T + alpha_T\n",
    "        # by registering it, you can later use it as self.alpha_t_list\n",
    "        self.register_buffer('alpha_t_list', alpha_t_list)\n",
    "\n",
    "    def get_alpha(self, t: int) -> Tuple[float, float]:\n",
    "        # given a particular denoising step t, return alpha_t and \\bar{alpha}_t\n",
    "        # we use a linear scheduler here\n",
    "        alpha_t = self.alpha_t_list[t, None, None, None]\n",
    "        alpha_bar_t = torch.cumprod(self.alpha_t_list, dim=0)[t, None, None, None]\n",
    "        return alpha_t.to(device), alpha_bar_t.to(device)\n",
    "\n",
    "    def forward_train(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        For forward diffusion process of a DDPM model. Refer to the training algorithms\n",
    "        on Page 36 and Page 38, respectively, for the x_zero and epsilon models.\n",
    "        \n",
    "        Input:\n",
    "          - x: x_0, clearn image, shape of BxCxHxW\n",
    "          \n",
    "        Output:\n",
    "          - loss: a scalar tensor of the loss between the UNet's output and the ground \n",
    "            truth defined in the DDPM variant (x_zero or epsilon)\n",
    "        \"\"\"\n",
    "        # randomly take a time step t between 1 to T\n",
    "        t = torch.randint(1, self.T + 1, (x.shape[0],)).to(x.device)\n",
    "\n",
    "        # get alpha_t and \\bar{alpha}_t\n",
    "        alpha_t, alpha_bar_t = self.get_alpha(t)\n",
    "\n",
    "        # sample noise epsilon ~ N(0, 1)\n",
    "        epsilon_t = torch.randn_like(x)\n",
    "        \n",
    "        loss = None\n",
    "        ###########################################################################\n",
    "        # TODO: Compute x_t according to the definition and feed it to the UNet   #\n",
    "        # to get the output, which will be compared with the ground truth         #\n",
    "        # according to the denoising objective.                                   #\n",
    "        ###########################################################################\n",
    "        raise NotImplementedError\n",
    "        ###########################################################################\n",
    "        #                             END OF YOUR CODE                            #\n",
    "        ###########################################################################\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward_test(self, num_samples: int=16, im_size: Tuple[int, int, int] = (1, 28, 28), store_interval=-1) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Inference behavior (denoising process) of the model.\n",
    "        \n",
    "        Inputs:\n",
    "          - num_samples: number of images to generate\n",
    "          - im_size: shape (C, H, W) of the generated images\n",
    "          - store_interval: frequency of storing the generated images along the denoising process\n",
    "          \n",
    "        Output:\n",
    "          - x_0: generated clean, noise-free images\n",
    "          - inter_x: generated intermediate images along the denoising process\n",
    "        \"\"\"\n",
    "        \n",
    "        # x_T ~ N(0, 1), a pure Gaussian noise image\n",
    "        x_t = torch.randn(num_samples, *im_size).to(device)\n",
    "\n",
    "        # clean, noise-free image\n",
    "        x_0 = None\n",
    "        # list to store those intermediate generated images\n",
    "        inter_x_list = []\n",
    "        \n",
    "        # gradually denoise the initial image x_t according to the denoising objective\n",
    "        for t in range(self.T, 0, -1):\n",
    "            # alpha\n",
    "            alpha_t, alpha_bar_t = self.get_alpha(t)\n",
    "            _, alpha_bar_t_1 = self.get_alpha(t - 1)\n",
    "            \n",
    "            ###########################################################################\n",
    "            # TODO: Implement the denoising process (inference algorithms) of DDPM    #\n",
    "            # according to the denoising objective.                                   #\n",
    "            ###########################################################################\n",
    "            raise NotImplementedError\n",
    "            ###########################################################################\n",
    "            #                             END OF YOUR CODE                            #\n",
    "            ###########################################################################\n",
    "\n",
    "            if t == 1 or (store_interval > 0 and t % store_interval == 0):\n",
    "                inter_x_list.append(x_t)\n",
    "\n",
    "        x_0 = x_t\n",
    "        if store_interval > 0:\n",
    "            assert len(inter_x_list) > 0\n",
    "            inter_x = torch.stack(inter_x_list, dim=0)\n",
    "        else:\n",
    "            inter_x = None\n",
    "\n",
    "        return x_0, inter_x\n",
    "\n",
    "    def forward(self, x: torch.Tensor = None, num_samples: int = 16, im_size: Tuple[int, int, int] = (1, 28, 28), store_interval=-1) -> torch.Tensor:\n",
    "        if self.training:\n",
    "            # raining-time behavior\n",
    "            assert x is not None\n",
    "            return self.forward_train(x)\n",
    "\n",
    "        # testing-time behavior\n",
    "        return self.forward_test(num_samples, im_size, store_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa00354",
   "metadata": {},
   "source": [
    "## <font color='red'> Task 3: Implementation of training and evaluation of a DDPM model (1 point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0af1c",
   "metadata": {
    "id": "18e0af1c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_eval_ddpm(dataloader, n_epoch: int, alpha_1, alpha_T, T, denoising_objective='x_zero') -> None:\n",
    "    \"\"\"\n",
    "    Training and evaluation of a DDPM model.\n",
    "    \n",
    "    Inputs:\n",
    "      - dataloader: SubMNIST data loader\n",
    "      - nepoch: number of epochs\n",
    "      - alpha_1: smallest alpha value\n",
    "      - alpha_T: largest alpha value\n",
    "      - T: number of denoising steps\n",
    "      - denoising_objective: x_zero or episolon\n",
    "      \n",
    "    output:\n",
    "      - ddpm: the trained DDPM model\n",
    "    \"\"\"\n",
    "    assert denoising_objective in ['x_zero', 'epsilon']\n",
    "    \n",
    "    ddpm = None\n",
    "    ###########################################################################\n",
    "    # TODO: Define a DDPM model.                                              #\n",
    "    ###########################################################################\n",
    "    raise NotImplementedError\n",
    "    ###########################################################################\n",
    "    #                             END OF YOUR CODE                            #\n",
    "    ###########################################################################\n",
    "    \n",
    "    ddpm.to(device)\n",
    "\n",
    "    # hard-coded learning rate\n",
    "    optim = torch.optim.Adam(ddpm.parameters(), lr=2e-4)\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        # set the ddpm to train\n",
    "        ddpm.train()\n",
    "        progress_bar = tqdm(dataloader)\n",
    "        # an exponential moving average with discount factor 0.1\n",
    "        total_loss = None \n",
    "        for x, _ in progress_bar:\n",
    "            optim.zero_grad()\n",
    "            x = x.to(device)\n",
    "            loss = ddpm(x)\n",
    "            loss.backward()\n",
    "            if total_loss is None:\n",
    "                total_loss = loss.item()\n",
    "            else:\n",
    "                # 10% from immediate loss and 90% from previous average\n",
    "                total_loss = 0.9 * total_loss + 0.1 * loss.item() \n",
    "            progress_bar.set_description(f\"epoch: {(i+1)}, loss: {total_loss:.4f}\")\n",
    "            optim.step()\n",
    "\n",
    "        # set the ddpm to eval\n",
    "        ddpm.eval()\n",
    "        with torch.no_grad():\n",
    "            xh, _ = ddpm(num_samples=16, im_size=(1, 28, 28))\n",
    "            grid = make_grid(xh, nrow=4, normalize=True)\n",
    "            plt.imshow(grid.cpu().numpy().transpose(1, 2, 0))\n",
    "            plt.show()\n",
    "\n",
    "    return ddpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oC08cI5cBTKJ",
   "metadata": {
    "id": "oC08cI5cBTKJ"
   },
   "outputs": [],
   "source": [
    "def generate_images(ddpm, im_size=(1, 28, 28), store_interval=-1) -> None:\n",
    "    # set the ddpm to eval\n",
    "    ddpm.eval()\n",
    "    with torch.no_grad():\n",
    "        xh, inter_x = ddpm(num_samples=4, im_size=im_size, store_interval=store_interval)\n",
    "        grid = make_grid(xh, nrow=4, normalize=True)\n",
    "        N, B, C, H, W = inter_x.shape\n",
    "        inter_x = inter_x.view(N * B, C, H, W)\n",
    "        inter_grid = make_grid(inter_x, nrow=B, normalize=True)\n",
    "\n",
    "    return grid, inter_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a5256",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "684a5256",
    "outputId": "3ee723c6-eb7f-4711-928b-00a2b4909e2b"
   },
   "outputs": [],
   "source": [
    "# read the MNIST dataset into a dataloader\n",
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))])\n",
    "dataset = SubsetMNIST(\n",
    "    \"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=tf,\n",
    ")\n",
    "mnist_dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff90f7",
   "metadata": {},
   "source": [
    "## <font color='red'> Task 4: Tuning the hyper parameters for the x_zero DDPM variant (2 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef7963",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6fef7963",
    "outputId": "5eba7028-1b2e-4651-d4b1-3d46dd6ed2dc"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "num_epochs = 5\n",
    "###########################################################################\n",
    "# TODO: Tune the hyper parameters of alpha_1 and alpha_T until you can    #\n",
    "# satisfied generation results (it is left vague for you to figure out).  #\n",
    "###########################################################################\n",
    "alpha_1 = 0.1\n",
    "alpha_T = 0.9\n",
    "###########################################################################\n",
    "#                             END OF YOUR CODE                            #\n",
    "###########################################################################\n",
    "T = 500\n",
    "denoising_objective = 'x_zero'\n",
    "ddpm_x_zero = train_eval_ddpm(dataloader=mnist_dataloader, n_epoch=num_epochs, alpha_1=alpha_1, alpha_T=alpha_T, T=T, denoising_objective=denoising_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-X6JkfC5BRPP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "-X6JkfC5BRPP",
    "outputId": "e6bf9ab2-d18f-4b23-afd9-5c7a8a829498"
   },
   "outputs": [],
   "source": [
    "# let's see how the denoising process works\n",
    "im_grid, inter_im_grid = generate_images(ddpm_x_zero, (1, 28, 28), T // 10)\n",
    "\n",
    "# final generated images\n",
    "plt.imshow(im_grid.cpu().numpy().transpose(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "# visualizations of the intermediate images\n",
    "# note there are negative values in the initial noisy images, with normalization,\n",
    "# the final clean images will look gray in the background (not very black)\n",
    "plt.imshow(inter_im_grid.cpu().numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f35903",
   "metadata": {},
   "source": [
    "## <font color='red'> Task 5: Briefly describe your experience and observations of tuning hyper parameters for the x_zero DDPM variant (1 point)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0de927",
   "metadata": {},
   "source": [
    "[Your answer]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b44fe7",
   "metadata": {},
   "source": [
    "## <font color='red'> Task 6: Tuning the hyper parameters for the epsilon DDPM variant (2 points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LrJrZ-9f4QcD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LrJrZ-9f4QcD",
    "outputId": "f26aa954-a072-4814-e8cb-8b0f1e7da5f0"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "###########################################################################\n",
    "# TODO: Tune the hyper parameters of alpha_1 and alpha_T until you can    #\n",
    "# satisfied generation results (it is left vague for you to figure out).  #\n",
    "###########################################################################\n",
    "alpha_1 = 0.1\n",
    "alpha_T = 0.9\n",
    "###########################################################################\n",
    "#                             END OF YOUR CODE                            #\n",
    "###########################################################################\n",
    "T = 1000\n",
    "denoising_objective = 'epsilon'\n",
    "ddpm_epsilon = train_eval_ddpm(dataloader=mnist_dataloader, n_epoch=num_epochs, alpha_1=alpha_1, alpha_T=alpha_T, T=T, denoising_objective=denoising_objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BauvW-NJYN99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "BauvW-NJYN99",
    "outputId": "59c0e8d1-a608-4ac8-92ca-f4c30541291a"
   },
   "outputs": [],
   "source": [
    "# let's see how the denoising process works\n",
    "im_grid, inter_im_grid = generate_images(ddpm_epsilon, (1, 28, 28), T // 10)\n",
    "\n",
    "# final generated images\n",
    "plt.imshow(im_grid.cpu().numpy().transpose(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "# visualizations of the intermediate images\n",
    "# note there are negative values in the initial noisy images, with normalization,\n",
    "# the final clean images will look gray in the background (not very black)\n",
    "plt.imshow(inter_im_grid.cpu().numpy().transpose(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f752241",
   "metadata": {},
   "source": [
    "## <font color='red'> Task 7: Briefly describe your experience and observations of tuning hyper parameters for the epsilon DDPM variant (1 point)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3101f306",
   "metadata": {},
   "source": [
    "[Your answer]:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
